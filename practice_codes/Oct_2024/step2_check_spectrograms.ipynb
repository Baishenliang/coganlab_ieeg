{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d9af99cc9066ab",
   "metadata": {},
   "source": "## Read the script"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from ieeg.io import get_data, raw_from_layout, save_derivative\n",
    "from ieeg.navigate import trial_ieeg, outliers_to_nan, channel_outlier_marker, crop_empty_data\n",
    "from ieeg.calc.scaling import rescale\n",
    "from ieeg.viz.ensemble import chan_grid\n",
    "from ieeg.timefreq.utils import crop_pad, wavelet_scaleogram\n",
    "from ieeg.viz.parula import parula_map\n",
    "save_dir='C:\\\\Users\\\\bl314\\\\Box\\\\CoganLab\\\\IndividualMeetings\\\\Baishen\\\\ieeg_results\\\\lexical_delay'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ddab12751f7eacd0",
   "metadata": {},
   "source": [
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "layout = get_data(\"LexicalDecRepDelay\", root=LAB_root)\n",
    "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
    "subject = subjects[0]\n",
    "\n",
    "if subject=='D0054':\n",
    "    subject_Tag = 'D54'\n",
    "if subject=='D0054':\n",
    "    subject_Tag = 'D54'\n",
    "elif subject=='D0055':\n",
    "    subject_Tag = 'D55'\n",
    "elif subject=='D0070':\n",
    "    subject_Tag = 'D70'\n",
    "elif subject=='D0070':\n",
    "    subject_Tag = 'D70'\n",
    "elif subject=='D0094':\n",
    "    subject_Tag = 'D94'\n",
    "elif subject=='D0101':\n",
    "    subject_Tag = 'D101'\n",
    "elif subject=='D0102':\n",
    "    subject_Tag = 'D102'\n",
    "elif subject=='D0103':\n",
    "    subject_Tag = 'D103'\n",
    "elif subject=='D0107':\n",
    "    subject_Tag = 'D107B'\n",
    "else:\n",
    "    print(\"Subject not found, please check.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f13a9a1c09fd5015",
   "metadata": {},
   "source": "## Plot subj"
  },
  {
   "cell_type": "code",
   "id": "2c1efaa3e16170ba",
   "metadata": {},
   "source": [
    "from ieeg.viz.mri import plot_subj\n",
    "\n",
    "# plot the subject brain\n",
    "fig1 = plot_subj(subject_Tag)\n",
    "#Label every electrode\n",
    "mne.viz.set_3d_view(fig1, azimuth=150, elevation=70, focalpoint=\"auto\",\n",
    "                    distance=\"auto\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc5af04c9c2a086d",
   "metadata": {},
   "source": [
    "## Load subj\n",
    "### <span style=\"color:red\">Please make sure that the **event.tsv** files in the **clean** derivatives do not contain **\"BAD boundary\"** lines, or remove them if they have</span>"
   ]
  },
  {
   "cell_type": "code",
   "id": "52b5e66bc1b432a5",
   "metadata": {},
   "source": "raw = raw_from_layout(layout.derivatives['derivatives/clean'], subject=subject, desc='clean',extension='.edf',preload=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c08d79928351d52b",
   "metadata": {},
   "source": [
    "## Remove eeg channels\n",
    "https://ieeg-pipelines.readthedocs.io/en/latest/auto_examples/plot_spectrograms.html\n",
    "### <span style=\"color:red\">Please pay attention to the section above and see what channels do not have locations when the raw was loaded. Write them down and remove them. They are usually EEG channels</span>"
   ]
  },
  {
   "cell_type": "code",
   "id": "6477cb1bb3233673",
   "metadata": {},
   "source": [
    "# Remove EEG channels for D101\n",
    "found=1\n",
    "if subject=='D0053':\n",
    "    eeg_channels_to_exclude=[]\n",
    "elif subject=='D0055':\n",
    "    eeg_channels_to_exclude=[]\n",
    "elif subject=='D0054':\n",
    "    eeg_channels_to_exclude=[]\n",
    "elif subject=='D0070':\n",
    "    eeg_channels_to_exclude=[]\n",
    "elif subject=='D0094':\n",
    "    eeg_channels_to_exclude=[]\n",
    "elif subject=='D0101':\n",
    "    eeg_channels_to_exclude = ['Fp1', 'Fp2', 'F3','F4','C3','C4','P3','P4','F7','F8','T3','T4','T5','T6','O1','O2','Fz','Cz','Pz']\n",
    "elif subject=='D0102':\n",
    "    eeg_channels_to_exclude = ['T5', 'T6', 'FZ', 'CZ', 'PZ', 'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', '02', 'F7', 'F8', 'T3', 'T4']\n",
    "elif subject=='D0103':\n",
    "    eeg_channels_to_exclude = ['FZ', 'CZ', 'PZ', 'F7', 'F8', 'T5', 'T6', 'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'T3', 'T4']\n",
    "elif subject=='D0107':\n",
    "    eeg_channels_to_exclude=[]\n",
    "else:\n",
    "    print(\"Subject not found, please check.\")\n",
    "    found=0\n",
    "    \n",
    "if found and eeg_channels_to_exclude:\n",
    "    raw.drop_channels(eeg_channels_to_exclude)\n",
    "#raw.load_data()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Remove outlier channels",
   "id": "8e7ef16eba910fd"
  },
  {
   "cell_type": "code",
   "id": "e9670152b4d4c4a6",
   "metadata": {},
   "source": [
    "# mark channel outliers as bad\n",
    "raw.info['bads'] = channel_outlier_marker(raw, 3, 2)\n",
    "# Exclude bad channels\n",
    "raw.drop_channels(raw.info['bads'])\n",
    "#raw.load_data()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wavelet spectrogram",
   "id": "d2e47178f74faab8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not os.path.exists(os.path.join(save_dir, subject)):\n",
    "    os.mkdir(os.path.join(save_dir, subject)) \n",
    "if not os.path.exists(os.path.join(save_dir, subject,'wavelet')):\n",
    "    os.mkdir(os.path.join(save_dir, subject,'wavelet'))\n",
    "if not os.path.exists(os.path.join(save_dir, subject,'multitaper')):\n",
    "    os.mkdir(os.path.join(save_dir, subject,'multitaper'))"
   ],
   "id": "86980e448c6aed08",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b797b0045922aa6",
   "metadata": {},
   "source": [
    "# Wavelet is good to detect and remove muscle artifact channels\n",
    "# Also plot the subject brain\n",
    "for task, task_Tag in zip(('Repeat','Yes_No'),('Rep','YN')):\n",
    "    for epoch, t, tag in zip(\n",
    "        ('Auditory_stim/'+task+'/CORRECT','Delay/'+task+'/CORRECT','Resp/'+task+'/CORRECT'),\n",
    "        ((-0.5, 1.5),(-0.5, 1.5),(-0.5, 1)),\n",
    "        ('Auditory-'+task_Tag,'Delay-'+task_Tag,'Resp-'+task_Tag)\n",
    "    ):\n",
    "        \n",
    "        # Get the spectras\n",
    "        t1 = t[0] - 0.5\n",
    "        t2 = t[1] + 0.5\n",
    "        times = (t1, t2)\n",
    "        trials = trial_ieeg(raw, epoch, times, preload=True)\n",
    "        outliers_to_nan(trials, outliers=10)\n",
    "        \n",
    "        ##############################\n",
    "        ####### Wavelet ##############\n",
    "        ##############################\n",
    "        \n",
    "        spectra_wavelet = wavelet_scaleogram(trials, n_jobs=-3, decim=int(\n",
    "            raw.info['sfreq'] / 200)) # 1/10 of the timepionts, don't take too long\n",
    "        crop_pad(spectra_wavelet, \"0.5s\") # cut the first and final 0.5s, change to zero\n",
    "        \n",
    "        # Get the baseline\n",
    "        if epoch=='Auditory_stim/'+task+'/CORRECT':\n",
    "            base_wavelet = spectra_wavelet.copy().crop(-0.5, 0)\n",
    "            base_wavelet = base_wavelet.average(lambda x: np.nanmean(x, axis=0), copy=True)\n",
    "        \n",
    "        # Baseline correction\n",
    "        spectra_wavelet = spectra_wavelet.average(lambda x: np.nanmean(x, axis=0), copy=True)   \n",
    "        spectra_wavelet = rescale(spectra_wavelet, base_wavelet, copy=True, mode='ratio')\n",
    "        spectra_wavelet._data = np.log10(spectra_wavelet._data) * 20\n",
    "    \n",
    "        # Save spectras\n",
    "        filename = os.path.join(save_dir, subject,'wavelet',f'{tag}-tfr.h5')\n",
    "        mne.time_frequency.write_tfrs(filename, spectra_wavelet, overwrite=True)\n",
    "        \n",
    "        # Make spectrograms\n",
    "        chan_grids=chan_grid(spectra_wavelet, size = (20,10),vlim=(-2, 2), cmap=parula_map)\n",
    "    \n",
    "        # Save spectrograms\n",
    "        fig_count=0\n",
    "        for fig in chan_grids:\n",
    "            figdir = os.path.join(save_dir, subject,'wavelet',f'{tag}_{fig_count+1}.jpg')\n",
    "            chan_grids[fig_count].savefig(figdir,dpi=300)   \n",
    "            fig_count+=1\n",
    "            \n",
    "        # Clean memory\n",
    "        del spectra_wavelet,filename\n",
    "        \n",
    "        ##############################\n",
    "        ####### Multitapper ##########\n",
    "        ##############################\n",
    "        \n",
    "        freq = np.linspace(0.5, 200, num=80)\n",
    "        kwargs = dict(average=False, n_jobs=-3, freqs=freq, return_itc=False,\n",
    "                      n_cycles=freq/2, time_bandwidth=4,\n",
    "                      # n_fft=int(trials.info['sfreq'] * 2.75),\n",
    "                      decim=20, )\n",
    "                      # adaptive=True)\n",
    "        spectra_multitaper = trials.compute_tfr(method=\"multitaper\",  **kwargs)\n",
    "        crop_pad(spectra_multitaper, \"0.5s\") # cut the first and final 0.5s, change to zero\n",
    "        \n",
    "                # Get the baseline\n",
    "        if epoch=='Auditory_stim/'+task+'/CORRECT':\n",
    "            base_multitaper = spectra_multitaper.copy().crop(-0.5, 0)\n",
    "            base_multitaper = base_multitaper.average(lambda x: np.nanmean(x, axis=0), copy=True)\n",
    " \n",
    "        # Baseline correction\n",
    "        spectra_multitaper = spectra_multitaper.average(lambda x: np.nanmean(x, axis=0), copy=True)   \n",
    "        spectra_multitaper = rescale(spectra_multitaper, base_multitaper, copy=True, mode='ratio')\n",
    "        \n",
    "        # Save spectras\n",
    "        filename = os.path.join(save_dir, subject,'multitaper',f'{tag}-tfr.h5')\n",
    "        mne.time_frequency.write_tfrs(filename, spectra_multitaper, overwrite=True)\n",
    "        \n",
    "        # Make spectrograms\n",
    "        chan_grids=chan_grid(spectra_multitaper, size = (20,10),vlim=(0.7, 1.4), cmap=parula_map)\n",
    "        \n",
    "        # Save spectrograms\n",
    "        fig_count=0\n",
    "        for fig in chan_grids:\n",
    "            figdir = os.path.join(save_dir, subject,'multitaper',f'{tag}_{fig_count+1}.jpg')\n",
    "            chan_grids[fig_count].savefig(figdir,dpi=300)   \n",
    "            fig_count+=1\n",
    "        \n",
    "        del trials,spectra_multitaper,filename\n",
    "    del base_wavelet,base_multitaper"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c936801fd2a93d81",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
